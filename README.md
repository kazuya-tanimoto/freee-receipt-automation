# AI-Driven Development Guidelines
## Document Overview
### Purpose
To define a "repository map" where human developers and multiple AI agents can share the same information source and collaborate seamlessly on code, design, and operations.

### Expected Benefits
- Reduce onboarding time for new participants and minimize rework costs
- Improve LLM response accuracy through RAG utilization
- Prevent "documentation decay" by automatically checking differences and compatibility in CI

### Use Cases
- New product launch
- Refactoring existing repositories / OSS publication preparation
- During audits and security reviews (providing centralized evidence & ADR)

## 1. Structure Tree

```text
.
├ README.md
├ CHANGELOG.md
├ .devcontainer.json        # ← Optional
├ .github/
│   └ workflows/
├ src/
├ tests/
├ docs/
│   ├ overview.md
│   ├ requirements/
│   │   ├ spec/            # "Coarse-grained" requirements
│   │   └ backlog/         # PBI・GitHub Issue integration
│   ├ design/
│   │   ├ architecture/
│   │   ├ db/
│   │   └ ui/
│   ├ api/
│   ├ standards/
│   ├ test/
│   ├ ops/
│   └ adr/
└ ai/
    ├ system_prompt.md
    ├ glossary.yml
    ├ config/
    ├ prompts/
    ├ tasks/
    ├ context/
    ├ examples/            # ← Optional
    ├ feedback/            # ← Optional
    └ history/             # ← Optional
```

## 2. File/Directory Quick Reference
| Path | Required/Optional | Purpose | Main Contents | Maintenance Frequency |
|------|-----------|------|----------|-----------|
| `/README.md` | ✅ Required | TL;DR / Quick Start | 5-minute setup procedure | Each release |
| `/CHANGELOG.md` | ✅ Required | Version history (Keep‑a‑Changelog) | Added / Changed / Fixed | Each release |
| `Makefile` | ✅ Required | Common command collection | setup, test, embed, etc. | When adding features |
| `.github/workflows/` | ✅ Required | CI / CD & Security Hardening | Lint／Test／Deploy | Each update |
| `.devcontainer.json` | ✅ Required | Reproducible development environment | image／extensions | When environment changes |
| `docs/` | ✅ Required | Human & AI shared knowledge base | See section 3 | As needed |
| `ai/` | ✅ Required | AI meta-layer | See section 4 | As needed |
| `ai/context/` | ▶︎ Depends on project scale | Long-form background (for RAG) | When major policy changes |
| `ai/examples/` | ▶︎ Recommended | Collection of successful patterns | Best implementations | When PR is adopted |
| `ai/feedback/` | ▶︎ For auto-generation environments | AI output review results | Evaluation comments | Each PR |
| `ai/history/` | ▶︎ Optional | Session log & summary storage | Chat history JSON, daily digest | Auto-generated |
| `data-contract/` | ▶︎ Domain dependent | Data contract & schema compatibility guarantee | AsyncAPI, Avro schema | When schema changes |
| `benchmarks/` | ▶︎ Optional | Performance/cost comparison, evaluation reports | LLM inference cost table, execution time measurements | Regular measurement |

## 3. `docs/` — Human & AI Shared Knowledge Base

### 3.1 `overview.md`
Business background, goals, and constraints. Update when goals change.

### 3.2 `requirements/` — Two-layer Management

| Subpath | Usage | Operation |
|----------|------|------|
| `spec/` | Business requirements, non-functional requirements (`REQ‑001.md`, etc.) | When changes are confirmed ➡ Link with ADR |
| `backlog/` | PBI / Implementation task granularity (GitHub Issue ⇔ MD/YAML) | Auto-generated from issue template → closed |

> **FAQ**  
> **Are coarse-grained requirements and implementation tasks mixed?**  
> Framework specifications are in `spec/`, implementation instructions are in `backlog/`, enabling both static design documents and dynamic backlogs.

### 3.3 Other Subdirectories

| Path | Role | Notes |
|------|------|------|
| `design/architecture/` | C4 diagrams (Mermaid) | `.mmd`→SVG auto-generated by Actions |
| `api/` | `openapi.yaml` (SemVer) | MAJOR++ for breaking changes |
| `adr/` | MADR template (`nadr-2.1.2.md`) | 1 decision = 1 file |

**`adr/` Operation Rules**:
- **ID Assignment**: Use format `ADR-0001`, `ADR-0002` in sequential order
- **Maintenance**: Always add a new ADR for breaking changes or technology selection

## 4. `ai/` — AI Meta-layer

| Directory | Purpose | Maintenance Method |
|--------------|------|-----------|
| `system_prompt.md` | Common assumptions and prohibitions | Weekly review |
| `glossary.yml` | Domain terms ⇔ Class names | Add new terms |
| `prompts/` | Reusable templates | Test → Promotion |
| `tasks/` | Autonomous task definitions | When adding new flows |
| `context/` | Long-form background (for RAG) | When major policy changes |
| `examples/` | Successful patterns | When best practices are adopted |
| `feedback/` | AI output reviews | Bot saved |
| `history/` | sessions / summaries / insights | Nightly organization |

**`history/` Structure and Operation**:

| Subdirectory | Purpose | Example |
|-----------------|------|----|
| `sessions/` | Raw chat logs (JSON) | `2025-05-06T06:00:session.json` |
| `summaries/` | Markdown summaries of the above | `2025-05-06T06:00:summary.md` |
| `insights/` | Improvement points extracted by periodic batch | `2025-W19-insights.md` |

**Maintenance Method**:
- Automatically save to `sessions/` after session ends
- Generate `summaries/` daily via CRON
- Generate `insights/` weekly and transcribe to `ai/feedback/`

## 5. CI / Development Environment Points

- **Workflows**: `lint-and-test.yml`, `security-scan.yml`, `build-docker.yml`  
- **Schema diff**: Confluent Registry compatibility check  
- **DevContainer**: Centralized management of VS Code extensions, postCreate

## 6. Selectively Added Directories

| Path | Timing | Use Case |
|------|-----------|-------------|
| `docs/test/` | Test expansion | Test pyramid management |
| `docs/ops/` | Dedicated SRE | SLO / Runbook |
| `benchmarks/` | LLM measurement | OpenAI Evals, etc. |
| `data-contract/` | Event-driven | AsyncAPI / Avro |

### `data-contract/` Details
**Usage**:  
Store "contracts" between data producers and consumers as code. Prevent breaking changes similar to API contracts.
- **Placement**: `customer.avro`, `orders.proto`, `contract.md`, etc.
- **Maintenance Method**:
  1. Create PR when schema changes, run backward compatibility tests in CI
  2. Always include `BREAKING CHANGE` tag in release notes

### `benchmarks/` Details
**Usage**:  
Monitor LLM inference costs, performance, memory, etc. to provide decision-making material for model/prompt changes.
- **Placement**: `benchmark_2025-05.csv`, `plots/latency.png`, `README.md`
- **Maintenance Method**:
  1. Measure with `make benchmark` → Append to CSV
  2. Update graphs with Python script, attach to PR

## 7. Customization References

- **Bulletproof React** — Large-scale React configuration examples  
- **Naming Cheatsheet** — Clear naming guidelines  

## 8. Update Flow Summary

1. Issue / ADR for policy decisions  
2. PR: Implementation & documentation updates  
3. CI: Lint / Test / schema diff / Secret Scan  
4. Review & merge: Save summary to `ai/feedback/`  
5. Update CHANGELOG → Tag → Release  

## 9. Future Improvement Ideas

- Monitor latency and cost with `benchmarks/`  
- Automate Mermaid→SVG to eliminate diagram and source divergence  
- Track history with `version:` field in `ai/prompts/`